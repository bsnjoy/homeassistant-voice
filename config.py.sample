#!/usr/bin/env python
# Configuration file for speech detection and transcription system

TRANSCRIPTION_API_URL = "http://192.168.1.65:8889/transcribe"

# Home Assistant configuration.
# Generate Long-lived access token in the bottom of http://homeassistant.local:8123/profile/security
HOMEASSISTANT_URL = "http://192.168.1.66:8123"
HOMEASSISTANT_TOKEN = "YOUR LONG-LIVED ACCESS TOKEN"

OPENAI_API_KEY = "YOUR SAMPLE KEY"

# Audio recording configuration
RECORDINGS_DIR = "recordings"
SAVE_RECORDINGS_TO_DISK = False  # Set to True to save all recordings to disk
DB_THRESHOLD = 50  # Default speech detection threshold in dB
SILENCE_THRESHOLD_MS = 500  # Default silence duration threshold in ms
MIN_RECORDING_LENGTH_SEC = 1.0  # Minimum recording length to process
PREROLL_DURATION_SEC = 0.5  # Duration of audio to include before speech detection (in seconds)

# Path to sound file played after command execution or blank for no sound
HOMEASSISTANT_SOUND = "sounds/homeassistant.wav"
AI_SOUND = "sounds/ai.wav"


# Audio playback command
# Audio recording command for PulseAudio
# AUDIO_PLAY_CMD = ["paplay", "--property=media.role=announce", "--rate=44100", "--channels=1", "--format=s16le", "--raw", "--latency-msec", "10"]
# Audio recording command for ALSA (use this if PulseAudio is not available), for test in bash:
# aplay -D plughw:CARD=MS,DEV=0 sounds/command_completed.wav
# To get the list of available devices, run:
# arecord -L
# We use different commands because they can use different frequencies.
# Piper TTS 22050 Hz, but audio files are usually 44.1 kHz
VOICE_PLAY_CMD = ["aplay", "-D", "plughw:CARD=MS,DEV=0", "-r", "22050", "-c", "1", "-f", "S16_LE", "-t", "raw"]
AUDIO_PLAY_CMD = ["aplay", "-D", "plughw:CARD=MS,DEV=0", "-r", "44100", "-c", "1", "-f", "S16_LE", "-t", "raw"]

# Audio format configuration
SAMPLE_RATE = 16000
SAMPLE_WIDTH = 2  # 16-bit audio (S16_LE)
CHANNELS = 1

# TTS API configuration
TTS_API_URL = "192.168.1.65:5000"

# Audio recording command for PulseAudio
# AUDIO_RECORD_CMD = ["parecord", "--property=media.role=phone", f"--rate={SAMPLE_RATE}", f"--channels={CHANNELS}", "--format=s16le", "--raw", "--latency-msec", "10"]
# Audio recording command for ALSA (use this if PulseAudio is not available)
AUDIO_RECORD_CMD = ["arecord", "-D", "dsnoop:CARD=MS,DEV=0", "-r", str(SAMPLE_RATE), "-c", str(CHANNELS), "-f", "S16_LE", "-t", "raw"]

# AI assistant names for wake word detection. The first name is used as the default wake word
ai_assistant_names = ["умник", "бобер", "бобёр"]

# Commands configuration with separate aliases for actions, devices, and rooms

# Action aliases (turn on/off)
action_aliases = {
    "turn_on": ["turn on", "enable", "start", "включи", "включить", "запусти", "запустить"],
    "turn_off": ["turn off", "disable", "stop", "выключи", "выключить", "останови", "остановить"]
}

# Device aliases
device_aliases = {
    "ac": ["ac", "air conditioner", "air conditioning", "кондиционер", "кондер"],
    # Add more devices as needed
    # "light": ["light", "lamp", "свет", "лампа"],
    # "tv": ["tv", "television", "телевизор"]
}

# Room aliases
room_aliases = {
    "office": ["office", "офис", "кабинет"],
    # Add more rooms as needed
    # "bedroom": ["bedroom", "спальня"],
    # "living_room": ["living room", "гостиная"]
}

# Default room if not specified
default_room = "office"

# Devices that can be called without specifying a room
# These devices will be searched across all rooms
devices_without_room = ["ac"]

# Room to device mapping
# Structure: room -> device -> entity_id
room_entities = {
    "office": {
        "ac": "climate.faikin_office_mqtt_hvac",
        # Add more devices as needed
        # "light": "light.office_main",
        # "tv": "media_player.office_tv",
    },
    # Add more rooms as needed
    # "bedroom": {
    #     "ac": "climate.bedroom_ac",
    #     "light": "light.bedroom_main",
    # },
}
